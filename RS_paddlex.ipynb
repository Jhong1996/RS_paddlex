{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 常规赛：遥感影像地块分割baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 比赛页面传送门： [常规赛：遥感影像地块分割](https://aistudio.baidu.com/aistudio/competition/detail/63)\n",
    "\n",
    "### 欢迎参加 [飞桨领航团实战速成营](https://aistudio.baidu.com/aistudio/education/group/info/16606) 一起学习 ，欢迎一键三连 Fork~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 赛题介绍\n",
    "本赛题由 2020 CCF BDCI 遥感影像地块分割 初赛赛题改编而来。遥感影像地块分割, 旨在对遥感影像进行像素级内容解析，对遥感影像中感兴趣的类别进行提取和分类，在城乡规划、防汛救灾等领域具有很高的实用价值，在工业界也受到了广泛关注。现有的遥感影像地块分割数据处理方法局限于特定的场景和特定的数据来源，且精度无法满足需求。因此在实际应用中，仍然大量依赖于人工处理，需要消耗大量的人力、物力、财力。本赛题旨在衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果，利用人工智能技术，对多来源、多场景的异构遥感影像数据进行充分挖掘，打造高效、实用的算法，提高遥感影像的分析提取能力。\n",
    "赛题任务\n",
    "本赛题旨在对遥感影像进行像素级内容解析，并对遥感影像中感兴趣的类别进行提取和分类，以衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果。\n",
    "\n",
    "### 数据说明\n",
    "本赛题提供了多个地区已脱敏的遥感影像数据，各参赛选手可以基于这些数据构建自己的地块分割模型。\n",
    "\n",
    "### 训练数据集\n",
    "样例图片及其标注如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8087a965609d48a19a5e60f0330fa9054d04097644de48ffa3d557e7a8ad64ad)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d18664ecf0514cb686c95958d30bbf8a2f5efb0691bc4d66a5f6317ab511d6d0)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e42f2c222f204094ac3a0ea8582ca331b0452fb2b1704eabaae379d499906977)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d5260bd5a820486a85aeb2105adfb6fa10284bd94453459f892755bc43e10b8a)\n",
    "\n",
    "\n",
    "训练数据集文件名称：train_and_label.zip\n",
    "\n",
    "包含2个子文件，分别为：训练数据集（原始图片）文件、训练数据集（标注图片）文件，详细介绍如下：\n",
    "\n",
    "* **训练数据集**（原始图片）文件名称：img_train\n",
    "\n",
    "\t包含66,653张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，每张图片的名称形如T000123.jpg。\n",
    "* **训练数据集**（标注图片）文件名称：lab_train\n",
    "\n",
    "\t包含66,653张分辨率为2m/pixel，尺寸为256 * 256的PNG图片，每张图片的名称形如T000123.png。\n",
    "* **备注**： 全部PNG图片共包括4种分类，像素值分别为0、1、2、3。此外，像素值255为未标注区域，表示对应区域的所属类别并不确定，在评测中也不会考虑这部分区域。\n",
    "\n",
    "### 测试数据集\n",
    "测试数据集文件名称：img_test.zip，详细介绍如下：\n",
    "\n",
    "包含4,609张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，文件名称形如123.jpg。、\n",
    "### 数据增强工具\n",
    "PaTTA：由第三方开发者组织AgentMaker维护的Test-Time Augmentation库，可在测试时通过数据增强方式产生额外的推理结果，在此基础上进行投票即可获得更稳定的成绩表现。 https://github.com/AgentMaker/PaTTA\n",
    "\n",
    "RIFLE：由第三方开发者对ICML 2020中的《RIFLE: Backpropagation in Depth for Deep Transfer Learning through Re-Initializing the Fully-connected LayEr》论文所提供的封装版本，其通过对输出层多次重新初始化来使得深层backbone得到更充分的更新。 https://github.com/GT-ZhangAcer/RIFLE_Module\n",
    "\n",
    "### 提交内容及格式\n",
    "* 以zip压缩包形式提交结果文件，文件命名为 result.zip；\n",
    "* zip压缩包中的图片格式必须为单通道PNG；\n",
    "* PNG文件数需要与测试数据集中的文件数相同，且zip压缩包文件名需要与测试数据集中的文件名一一对应；\n",
    "* 单通道PNG图片中的像素值必须介于0~3之间，像素值不能为255。如果存在未标注区域，评测系统会自动忽略对应区域的提交结果。\n",
    "### 提交示例\n",
    "提交文件命名为：result.zip，zip文件的组织方式如下所示：\n",
    "\n",
    "```\n",
    "主目录                                                                        \n",
    "├── 1.png         #每个结果文件命名为：测试数据集图片名称+.png                      \n",
    "├── 2.png                                                              \n",
    "├── 3.png                                                    \n",
    "├── ...     \n",
    "```                                                \n",
    "    \n",
    "**备注**： 主目录中必须包含与测试数据集相同数目、名称相对应的单通道PNG图片，且每张单通道PNG图片中的像素值必须介于0~3之间，像素值不能为255。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 环境安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple\r\n",
    "!pip install imgaug -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\r\n",
    "import matplotlib\r\n",
    "import os\r\n",
    "import paddlex as pdx\r\n",
    "\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -q data/data80164/train_and_label.zip\r\n",
    "!unzip -q data/data80164/img_test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据处理\n",
    "项目使用**PaddleX**进行数据处理和训练，**PaddleX**的API说明文档传送门：[API说明文档](https://paddlex.readthedocs.io/zh_CN/develop/apis/index.html)\n",
    "\n",
    "对用于分割任务的数据进行操作。可以利用[paddlex.seg.transforms](https://paddlex.readthedocs.io/zh_CN/develop/apis/transforms/seg_transforms.html#paddlex-seg-transforms)中的Compose类将图像预处理/增强操作进行组合。\n",
    "\n",
    "* **RandomHorizontalFlip** 以一定的概率对图像进行水平翻转。\n",
    "* **Resize** 调整图像大小。\n",
    "* **RandomPaddingCrop** 对图像和标注图进行随机裁剪，当所需要的裁剪尺寸大于原图时，则进行padding操作，模型训练时的数据增强操作。\n",
    "* **RandomBlur** 以一定的概率对图像进行高斯模糊。\n",
    "* **RandomRotate** 对图像进行随机旋转，模型训练时的数据增强操作。目前支持多通道的RGB图像，例如支持多张RGB图像沿通道轴做concatenate后的图像数据，不支持通道数量不是3的倍数的图像数据。\n",
    "* **RandomDistort** 以一定的概率对图像进行随机像素内容变换，模型训练时的数据增强操作。目前支持多通道的RGB图像，例如支持多张RGB图像沿通道轴做concatenate后的图像数据，不支持通道数量不是3的倍数的图像数据。\n",
    "* **Normalize** 对图像进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'paddlex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b901a525391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 定义训练和验证时的transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_transforms = transforms.Compose([\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paddlex'"
     ]
    }
   ],
   "source": [
    "from paddlex.seg import transforms\r\n",
    "import imgaug.augmenters as iaa\r\n",
    "\r\n",
    "# 定义训练和验证时的transforms\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    transforms.RandomHorizontalFlip(),            # 水平翻转\r\n",
    "    transforms.Resize(target_size=300),           # 调整图像大小\r\n",
    "    transforms.RandomPaddingCrop(crop_size=256),  # 随机剪裁\r\n",
    "    transforms.RandomBlur(prob=0.1),              # 高斯模糊\r\n",
    "    transforms.RandomRotate(rotate_range=15),     # 随机旋转\r\n",
    "    # transforms.RandomDistort(brightness_range=0.5),  # 随机变换\r\n",
    "    transforms.Normalize()                        # 标准化\r\n",
    "])\r\n",
    "eval_transforms = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.Normalize()\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 66652\n",
      "img_train/T096496.jpg\n",
      "lab_train/T096496.png\n",
      "('img_train/T074583.jpg', 'lab_train/T074583.png')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "datas = []\r\n",
    "image_base = 'img_train'   # 训练集原图路径\r\n",
    "annos_base = 'lab_train'   # 训练集标签路径\r\n",
    "\r\n",
    "# 读取原图文件名\r\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\r\n",
    "\r\n",
    "# 将训练集的图像集和标签路径写入datas中\r\n",
    "for id_ in ids_:\r\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))\r\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\r\n",
    "    datas.append((img_pt0.replace('/home/aistudio', ''), img_pt1.replace('/home/aistudio', '')))\r\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):\r\n",
    "        pass\r\n",
    "    else:\r\n",
    "        raise \"path invalid!\"\r\n",
    "\r\n",
    "# 打印datas的长度和具体存储例子\r\n",
    "print('total:', len(datas))\r\n",
    "print(datas[0][0])\r\n",
    "print(datas[0][1])\r\n",
    "print(datas[10][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 63320\n",
      "valid: 3332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# 四类标签，这里用处不大，比赛评测是以0、1、2、3类来对比评测的\r\n",
    "labels = ['建筑', '耕地', '林地',  '其他']\r\n",
    "\r\n",
    "# 将labels写入标签文件\r\n",
    "with open('labels.txt', 'w') as f:\r\n",
    "    for v in labels:\r\n",
    "        f.write(v+'\\n')\r\n",
    "\r\n",
    "# 随机打乱datas\r\n",
    "np.random.seed(5)\r\n",
    "np.random.shuffle(datas)\r\n",
    "\r\n",
    "# 验证集与训练集的划分，0.05表示5%为训练集，95%为训练集\r\n",
    "split_num = int(0.05*len(datas))\r\n",
    "\r\n",
    "# 划分训练集和验证集\r\n",
    "train_data = datas[:-split_num]\r\n",
    "valid_data = datas[-split_num:]\r\n",
    "\r\n",
    "# 写入训练集list\r\n",
    "with open('train_list.txt', 'w') as f:\r\n",
    "    for img, lbl in train_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 写入验证集list\r\n",
    "with open('valid_list.txt', 'w') as f:\r\n",
    "    for img, lbl in valid_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 打印训练集和测试集大小\r\n",
    "print('train:', len(train_data))\r\n",
    "print('valid:', len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "读取语义分割任务数据集，可使用[paddlex.datasets.SegDataset](https://paddlex.readthedocs.io/zh_CN/develop/apis/datasets.html#paddlex-datasets-segdataset)\n",
    "\n",
    "**paddlex.datasets.SegDataset**参数说明：\n",
    "* **data_dir (str)**: 数据集所在的目录路径。\n",
    "* **file_list (str)**: 描述数据集图片文件和对应标注文件的文件路径（文本内每行路径为相对data_dir的相对路径）。\n",
    "* **label_list (str)**: 描述数据集包含的类别信息文件路径。\n",
    "* **transforms (paddlex.seg.transforms)**: 数据集中每个样本的预处理/增强算子，详见[paddlex.seg.transforms](https://paddlex.readthedocs.io/zh_CN/develop/apis/transforms/seg_transforms.html#paddlex-seg-transforms)。\n",
    "* **num_workers (int|str)**：数据集中样本在预处理过程中的线程或进程数。默认为’auto’。当设为’auto’时，根据系统的实际CPU核数设置num_workers: 如果CPU核数的一半大于8，则num_workers为8，否则为CPU核数的一半。\n",
    "* **buffer_size (int)**: 数据集中样本在预处理过程中队列的缓存长度，以样本数为单位。默认为100。\n",
    "* **parallel_method (str)**: 数据集中样本在预处理过程中并行处理的方式，支持’thread’线程和’process’进程两种方式。默认为’process’（Windows和Mac下会强制使用thread，该参数无效）。\n",
    "* **shuffle (bool)**: 是否需要对数据集中样本打乱顺序。默认为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 11:16:42 [INFO]\t63320 samples in file train_list.txt\n",
      "2021-04-11 11:16:42 [INFO]\t3332 samples in file valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\r\n",
    "\r\n",
    "# 定义训练和验证数据集\r\n",
    "train_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,                # 数据集路径\r\n",
    "    file_list='train_list.txt',       # 训练集图片文件list路径\r\n",
    "    label_list='labels.txt',          # 训练集标签文件list路径\r\n",
    "    transforms=train_transforms,      # train_transforms\r\n",
    "    shuffle=True)                     # 数据集是否打乱\r\n",
    "    \r\n",
    "eval_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,                # 数据集路径\r\n",
    "    file_list='valid_list.txt',       # 验证集图片文件list路径\r\n",
    "    label_list='labels.txt',          # 验证集标签文件list路径\r\n",
    "    transforms=eval_transforms)       # eval_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型训练\n",
    "\n",
    "利用[paddlex.seg.DeepLabv3p](https://paddlex.readthedocs.io/zh_CN/develop/apis/models/semantic_segmentation.html)构建DeepLabv3p分割器。\n",
    "\n",
    "**paddlex.seg.DeepLabv3p**参数说明：\n",
    "* **num_classes (int)**: 类别数。\n",
    "* **backbone (str)**: DeepLabv3+的backbone网络，实现特征图的计算，取值范围为[’Xception65’, ‘Xception41’, ‘MobileNetV2_x0.25’, ‘MobileNetV2_x0.5’, ‘MobileNetV2_x1.0’, ‘MobileNetV2_x1.5’, ‘MobileNetV2_x2.0’, ‘MobileNetV3_large_x1_0_ssld’]，默认值为’MobileNetV2_x1.0’。\n",
    "* **output_stride (int)**: backbone 输出特征图相对于输入的下采样倍数，一般取值为8或16。默认16。\n",
    "* **aspp_with_sep_conv (bool)**: aspp模块是否采用separable convolutions。默认True。\n",
    "* **decoder_use_sep_conv (bool)**： decoder模块是否采用separable convolutions。默认True。\n",
    "* **encoder_with_aspp (bool)**: 是否在encoder阶段采用aspp模块。默认True。\n",
    "* **enable_decoder (bool)**: 是否使用decoder模块。默认True。\n",
    "* **use_bce_loss (bool)**: 是否使用bce loss作为网络的损失函数，只能用于两类分割。可与dice loss同时使用。默认False。\n",
    "* **use_dice_loss (bool)**: 是否使用dice loss作为网络的损失函数，只能用于两类分割，可与bce loss同时使用，当use_bce_loss和use_dice_loss都为False时，使用交叉熵损失函数。默认False。\n",
    "* **class_weight (list/str)**: 交叉熵损失函数各类损失的权重。当class_weight为list的时候，长度应为num_classes。当class_weight为str时， weight.lower()应为’dynamic’，这时会根据每一轮各类像素的比重自行计算相应的权重，每一类的权重为：每类的比例 * num_classes。class_weight取默认值None是，各类的权重1，即平时使用的交叉熵损失函数。\n",
    "* **ignore_index (int)**: label上忽略的值，label为ignore_index的像素不参与损失函数的计算。默认255。\n",
    "* **pooling_crop_size (int)**：当backbone为MobileNetV3_large_x1_0_ssld时，需设置为训练过程中模型输入大小，格式为[W, H]。例如模型输入大小为[512, 512], 则pooling_crop_size应该设置为[512, 512]。在encoder模块中获取图像平均值时被用到，若为None，则直接求平均值；若为模型输入大小，则使用avg_pool算子得到平均值。默认值None。\n",
    "* **input_channel (int)**: 输入图像通道数。默认值3。\n",
    "\n",
    "**DeepLabv3p**模型的训练接口，函数内置了**polynomial**学习率衰减策略和**momentum**优化器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**train**参数说明：\n",
    "* **num_epochs (int)**: 训练迭代轮数。\n",
    "* **train_dataset (paddlex.datasets)**: 训练数据读取器。\n",
    "* **train_batch_size (int)**: 训练数据batch大小。同时作为验证数据batch大小。默认2。\n",
    "* **eval_dataset (paddlex.datasets)**: 评估数据读取器。\n",
    "* **save_interval_epochs (int)**: 模型保存间隔（单位：迭代轮数）。默认为1。\n",
    "* **log_interval_steps (int)**: 训练日志输出间隔（单位：迭代次数）。默认为2。\n",
    "* **save_dir (str)**: 模型保存路径。默认’output’\n",
    "* **pretrain_weights (str)**: 若指定为路径时，则加载路径下预训练模型；若为字符串’IMAGENET’，则自动下载在ImageNet图片数据上预训练的模型权重；若为字符串’COCO’，则自动下载在COCO数据集上预训练的模型权重（注意：暂未提供Xception41、MobileNetV2_x0.25、MobileNetV2_x0.5、MobileNetV2_x1.5、MobileNetV2_x2.0的COCO预训练模型）；若为字符串’CITYSCAPES’，则自动下载在CITYSCAPES数据集上预训练的模型权重（注意：暂未提供Xception41、MobileNetV2_x0.25、MobileNetV2_x0.5、MobileNetV2_x1.5、MobileNetV2_x2.0的CITYSCAPES预训练模型）；若为None，则不使用预训练模型。默认’IMAGENET’。\n",
    "* **optimizer (paddle.fluid.optimizer)**: 优化器。当该参数为None时，使用默认的优化器：使用fluid.optimizer.Momentum优化方法，polynomial的学习率衰减策略。\n",
    "* **learning_rate (float)**: 默认优化器的初始学习率。默认0.01。\n",
    "* **lr_decay_power (float)**: 默认优化器学习率衰减指数。默认0.9。\n",
    "* **use_vdl (bool)**: 是否使用VisualDL进行可视化。默认False。\n",
    "* **sensitivities_file (str)**: 若指定为路径时，则加载路径下敏感度信息进行裁剪；若为字符串’DEFAULT’，则自动下载在Cityscapes图片数据上获得的敏感度信息进行裁剪；若为None，则不进行裁剪。默认为None。\n",
    "* **eval_metric_loss (float)**: 可容忍的精度损失。默认为0.05。\n",
    "* **early_stop (bool)**: 是否使用提前终止训练策略。默认值为False。\n",
    "* **early_stop_patience (int)**: 当使用提前终止训练策略时，如果验证集精度在early_stop_patience个epoch内连续下降或持平，则终止训练。默认值为5。\n",
    "* **resume_checkpoint (str)**: 恢复训练时指定上次训练保存的模型路径。若为None，则不会恢复训练。默认值为None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/xception.py:316\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/model_utils/loss.py:74\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "2021-04-11 11:17:14,759 - INFO - If regularizer of a Parameter has been set by 'fluid.ParamAttr' or 'fluid.WeightNormParamAttr' already. The Regularization[L2Decay, regularization_coeff=0.000040] in Optimizer will not take effect, and it will only be applied to other Parameters!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 11:17:18 [WARNING]\tPath of pretrain_weights('output/deeplab/best_model') is not exists!\n",
      "2021-04-11 11:17:18 [WARNING]\tPretrain_weights will be forced to set as 'IMAGENET', if you don't want to use pretrain weights, set pretrain_weights=None.\n",
      "2021-04-11 11:17:18 [INFO]\tDecompressing output/deeplab/pretrain/Xception65_deeplab_pretrained.tar...\n",
      "2021-04-11 11:17:24 [INFO]\tLoad pretrain weights from output/deeplab/pretrain/Xception65_deeplab_pretrained.\n",
      "2021-04-11 11:17:25 [INFO]\tThere are 660 varaibles in output/deeplab/pretrain/Xception65_deeplab_pretrained are loaded.\n",
      "2021-04-11 11:18:04 [INFO]\t[TRAIN] Epoch=1/2, Step=200/7915, loss=1.38414, lr=0.000198, time_each_step=0.16s, eta=0:41:56\n",
      "2021-04-11 11:18:35 [INFO]\t[TRAIN] Epoch=1/2, Step=400/7915, loss=1.215352, lr=0.000195, time_each_step=0.16s, eta=0:41:23\n",
      "2021-04-11 11:19:07 [INFO]\t[TRAIN] Epoch=1/2, Step=600/7915, loss=1.557952, lr=0.000193, time_each_step=0.16s, eta=0:40:43\n",
      "2021-04-11 11:19:39 [INFO]\t[TRAIN] Epoch=1/2, Step=800/7915, loss=1.168222, lr=0.000191, time_each_step=0.16s, eta=0:40:44\n",
      "2021-04-11 11:20:11 [INFO]\t[TRAIN] Epoch=1/2, Step=1000/7915, loss=1.645874, lr=0.000189, time_each_step=0.16s, eta=0:40:32\n",
      "2021-04-11 11:20:42 [INFO]\t[TRAIN] Epoch=1/2, Step=1200/7915, loss=0.966225, lr=0.000186, time_each_step=0.16s, eta=0:38:58\n",
      "2021-04-11 11:21:14 [INFO]\t[TRAIN] Epoch=1/2, Step=1400/7915, loss=0.866688, lr=0.000184, time_each_step=0.16s, eta=0:39:17\n",
      "2021-04-11 11:21:46 [INFO]\t[TRAIN] Epoch=1/2, Step=1600/7915, loss=0.882716, lr=0.000182, time_each_step=0.16s, eta=0:38:51\n",
      "2021-04-11 11:22:17 [INFO]\t[TRAIN] Epoch=1/2, Step=1800/7915, loss=1.114623, lr=0.000179, time_each_step=0.16s, eta=0:38:18\n",
      "2021-04-11 11:22:49 [INFO]\t[TRAIN] Epoch=1/2, Step=2000/7915, loss=1.28874, lr=0.000177, time_each_step=0.16s, eta=0:37:56\n",
      "2021-04-11 11:23:21 [INFO]\t[TRAIN] Epoch=1/2, Step=2200/7915, loss=0.928076, lr=0.000175, time_each_step=0.16s, eta=0:36:57\n",
      "2021-04-11 11:23:53 [INFO]\t[TRAIN] Epoch=1/2, Step=2400/7915, loss=1.219344, lr=0.000173, time_each_step=0.16s, eta=0:37:17\n",
      "2021-04-11 11:24:25 [INFO]\t[TRAIN] Epoch=1/2, Step=2600/7915, loss=0.707001, lr=0.00017, time_each_step=0.16s, eta=0:36:31\n",
      "2021-04-11 11:24:56 [INFO]\t[TRAIN] Epoch=1/2, Step=2800/7915, loss=0.805735, lr=0.000168, time_each_step=0.16s, eta=0:34:44\n",
      "2021-04-11 11:25:28 [INFO]\t[TRAIN] Epoch=1/2, Step=3000/7915, loss=0.92438, lr=0.000166, time_each_step=0.16s, eta=0:34:48\n",
      "2021-04-11 11:26:00 [INFO]\t[TRAIN] Epoch=1/2, Step=3200/7915, loss=0.748584, lr=0.000163, time_each_step=0.16s, eta=0:35:46\n",
      "2021-04-11 11:26:32 [INFO]\t[TRAIN] Epoch=1/2, Step=3400/7915, loss=0.929968, lr=0.000161, time_each_step=0.16s, eta=0:34:15\n",
      "2021-04-11 11:27:04 [INFO]\t[TRAIN] Epoch=1/2, Step=3600/7915, loss=0.890317, lr=0.000159, time_each_step=0.16s, eta=0:33:33\n",
      "2021-04-11 11:27:36 [INFO]\t[TRAIN] Epoch=1/2, Step=3800/7915, loss=1.239681, lr=0.000156, time_each_step=0.16s, eta=0:33:4\n",
      "2021-04-11 11:28:08 [INFO]\t[TRAIN] Epoch=1/2, Step=4000/7915, loss=0.826605, lr=0.000154, time_each_step=0.16s, eta=0:32:41\n",
      "2021-04-11 11:28:39 [INFO]\t[TRAIN] Epoch=1/2, Step=4200/7915, loss=0.865581, lr=0.000152, time_each_step=0.16s, eta=0:31:55\n",
      "2021-04-11 11:29:11 [INFO]\t[TRAIN] Epoch=1/2, Step=4400/7915, loss=1.006067, lr=0.000149, time_each_step=0.16s, eta=0:31:50\n",
      "2021-04-11 11:29:43 [INFO]\t[TRAIN] Epoch=1/2, Step=4600/7915, loss=0.659603, lr=0.000147, time_each_step=0.16s, eta=0:30:7\n",
      "2021-04-11 11:30:15 [INFO]\t[TRAIN] Epoch=1/2, Step=4800/7915, loss=0.81958, lr=0.000144, time_each_step=0.16s, eta=0:30:49\n",
      "2021-04-11 11:30:47 [INFO]\t[TRAIN] Epoch=1/2, Step=5000/7915, loss=0.905897, lr=0.000142, time_each_step=0.16s, eta=0:30:27\n",
      "2021-04-11 11:31:19 [INFO]\t[TRAIN] Epoch=1/2, Step=5200/7915, loss=1.311562, lr=0.00014, time_each_step=0.16s, eta=0:29:27\n",
      "2021-04-11 11:31:51 [INFO]\t[TRAIN] Epoch=1/2, Step=5400/7915, loss=0.674437, lr=0.000137, time_each_step=0.16s, eta=0:28:43\n",
      "2021-04-11 11:32:23 [INFO]\t[TRAIN] Epoch=1/2, Step=5600/7915, loss=0.733265, lr=0.000135, time_each_step=0.16s, eta=0:28:14\n",
      "2021-04-11 11:32:55 [INFO]\t[TRAIN] Epoch=1/2, Step=5800/7915, loss=0.861897, lr=0.000133, time_each_step=0.16s, eta=0:28:6\n",
      "2021-04-11 11:33:59 [INFO]\t[TRAIN] Epoch=1/2, Step=6200/7915, loss=0.989089, lr=0.000128, time_each_step=0.16s, eta=0:27:6\n",
      "2021-04-11 11:34:31 [INFO]\t[TRAIN] Epoch=1/2, Step=6400/7915, loss=0.84361, lr=0.000125, time_each_step=0.16s, eta=0:26:1\n",
      "2021-04-11 11:35:03 [INFO]\t[TRAIN] Epoch=1/2, Step=6600/7915, loss=0.689072, lr=0.000123, time_each_step=0.16s, eta=0:25:36\n",
      "2021-04-11 11:35:35 [INFO]\t[TRAIN] Epoch=1/2, Step=6800/7915, loss=1.421564, lr=0.000121, time_each_step=0.16s, eta=0:24:57\n",
      "2021-04-11 11:36:07 [INFO]\t[TRAIN] Epoch=1/2, Step=7000/7915, loss=0.871975, lr=0.000118, time_each_step=0.16s, eta=0:24:28\n",
      "2021-04-11 11:36:39 [INFO]\t[TRAIN] Epoch=1/2, Step=7200/7915, loss=0.909352, lr=0.000116, time_each_step=0.16s, eta=0:23:51\n",
      "2021-04-11 11:37:11 [INFO]\t[TRAIN] Epoch=1/2, Step=7400/7915, loss=0.527081, lr=0.000113, time_each_step=0.16s, eta=0:23:39\n",
      "2021-04-11 11:37:43 [INFO]\t[TRAIN] Epoch=1/2, Step=7600/7915, loss=1.336414, lr=0.000111, time_each_step=0.16s, eta=0:22:58\n",
      "2021-04-11 11:38:15 [INFO]\t[TRAIN] Epoch=1/2, Step=7800/7915, loss=0.702817, lr=0.000109, time_each_step=0.16s, eta=0:22:26\n",
      "2021-04-11 11:38:33 [INFO]\t[TRAIN] Epoch 1 finished, loss=1.01039, lr=0.000154 .\n",
      "2021-04-11 11:38:55 [INFO]\t[TRAIN] Epoch=2/2, Step=85/7915, loss=0.870395, lr=0.000106, time_each_step=0.16s, eta=0:22:34\n",
      "2021-04-11 11:39:27 [INFO]\t[TRAIN] Epoch=2/2, Step=285/7915, loss=0.851829, lr=0.000104, time_each_step=0.16s, eta=0:21:3\n",
      "2021-04-11 11:39:59 [INFO]\t[TRAIN] Epoch=2/2, Step=485/7915, loss=1.170004, lr=0.000101, time_each_step=0.16s, eta=0:20:57\n",
      "2021-04-11 11:40:30 [INFO]\t[TRAIN] Epoch=2/2, Step=685/7915, loss=1.095368, lr=9.9e-05, time_each_step=0.16s, eta=0:20:14\n",
      "2021-04-11 11:41:03 [INFO]\t[TRAIN] Epoch=2/2, Step=885/7915, loss=0.730491, lr=9.6e-05, time_each_step=0.16s, eta=0:19:55\n",
      "2021-04-11 11:41:34 [INFO]\t[TRAIN] Epoch=2/2, Step=1085/7915, loss=0.57304, lr=9.4e-05, time_each_step=0.16s, eta=0:19:3\n",
      "2021-04-11 11:42:06 [INFO]\t[TRAIN] Epoch=2/2, Step=1285/7915, loss=0.802685, lr=9.1e-05, time_each_step=0.16s, eta=0:18:45\n",
      "2021-04-11 11:42:38 [INFO]\t[TRAIN] Epoch=2/2, Step=1485/7915, loss=1.274061, lr=8.9e-05, time_each_step=0.16s, eta=0:18:1\n",
      "2021-04-11 11:43:10 [INFO]\t[TRAIN] Epoch=2/2, Step=1685/7915, loss=0.934664, lr=8.6e-05, time_each_step=0.16s, eta=0:17:34\n",
      "2021-04-11 11:43:42 [INFO]\t[TRAIN] Epoch=2/2, Step=1885/7915, loss=0.491202, lr=8.4e-05, time_each_step=0.16s, eta=0:16:50\n",
      "2021-04-11 11:44:14 [INFO]\t[TRAIN] Epoch=2/2, Step=2085/7915, loss=0.413462, lr=8.1e-05, time_each_step=0.16s, eta=0:16:26\n",
      "2021-04-11 11:44:45 [INFO]\t[TRAIN] Epoch=2/2, Step=2285/7915, loss=1.171786, lr=7.9e-05, time_each_step=0.16s, eta=0:16:11\n",
      "2021-04-11 11:45:17 [INFO]\t[TRAIN] Epoch=2/2, Step=2485/7915, loss=1.260185, lr=7.6e-05, time_each_step=0.16s, eta=0:15:45\n",
      "2021-04-11 11:45:49 [INFO]\t[TRAIN] Epoch=2/2, Step=2685/7915, loss=0.830991, lr=7.4e-05, time_each_step=0.16s, eta=0:15:3\n",
      "2021-04-11 11:46:21 [INFO]\t[TRAIN] Epoch=2/2, Step=2885/7915, loss=0.943867, lr=7.1e-05, time_each_step=0.16s, eta=0:14:25\n",
      "2021-04-11 11:46:53 [INFO]\t[TRAIN] Epoch=2/2, Step=3085/7915, loss=0.649991, lr=6.9e-05, time_each_step=0.16s, eta=0:13:54\n",
      "2021-04-11 11:47:25 [INFO]\t[TRAIN] Epoch=2/2, Step=3285/7915, loss=0.522893, lr=6.6e-05, time_each_step=0.16s, eta=0:13:22\n",
      "2021-04-11 11:47:57 [INFO]\t[TRAIN] Epoch=2/2, Step=3485/7915, loss=1.294366, lr=6.4e-05, time_each_step=0.16s, eta=0:12:48\n",
      "2021-04-11 11:48:29 [INFO]\t[TRAIN] Epoch=2/2, Step=3685/7915, loss=1.523792, lr=6.1e-05, time_each_step=0.16s, eta=0:12:25\n",
      "2021-04-11 11:49:01 [INFO]\t[TRAIN] Epoch=2/2, Step=3885/7915, loss=0.762807, lr=5.8e-05, time_each_step=0.16s, eta=0:11:50\n",
      "2021-04-11 11:49:33 [INFO]\t[TRAIN] Epoch=2/2, Step=4085/7915, loss=0.381855, lr=5.6e-05, time_each_step=0.16s, eta=0:11:15\n",
      "2021-04-11 11:50:05 [INFO]\t[TRAIN] Epoch=2/2, Step=4285/7915, loss=0.716054, lr=5.3e-05, time_each_step=0.16s, eta=0:10:42\n",
      "2021-04-11 11:50:37 [INFO]\t[TRAIN] Epoch=2/2, Step=4485/7915, loss=0.607137, lr=5.1e-05, time_each_step=0.16s, eta=0:10:12\n",
      "2021-04-11 11:51:08 [INFO]\t[TRAIN] Epoch=2/2, Step=4685/7915, loss=1.013862, lr=4.8e-05, time_each_step=0.16s, eta=0:9:50\n",
      "2021-04-11 11:51:40 [INFO]\t[TRAIN] Epoch=2/2, Step=4885/7915, loss=0.97746, lr=4.5e-05, time_each_step=0.16s, eta=0:9:9\n",
      "2021-04-11 11:52:12 [INFO]\t[TRAIN] Epoch=2/2, Step=5085/7915, loss=0.651718, lr=4.2e-05, time_each_step=0.16s, eta=0:8:40\n",
      "2021-04-11 11:52:44 [INFO]\t[TRAIN] Epoch=2/2, Step=5285/7915, loss=0.566961, lr=4e-05, time_each_step=0.16s, eta=0:8:4\n",
      "2021-04-11 11:53:16 [INFO]\t[TRAIN] Epoch=2/2, Step=5485/7915, loss=0.855699, lr=3.7e-05, time_each_step=0.16s, eta=0:7:33\n",
      "2021-04-11 11:53:48 [INFO]\t[TRAIN] Epoch=2/2, Step=5685/7915, loss=0.531376, lr=3.4e-05, time_each_step=0.16s, eta=0:7:3\n",
      "2021-04-11 11:54:20 [INFO]\t[TRAIN] Epoch=2/2, Step=5885/7915, loss=0.692552, lr=3.2e-05, time_each_step=0.16s, eta=0:6:29\n",
      "2021-04-11 11:54:52 [INFO]\t[TRAIN] Epoch=2/2, Step=6085/7915, loss=0.976808, lr=2.9e-05, time_each_step=0.16s, eta=0:6:1\n",
      "2021-04-11 11:55:24 [INFO]\t[TRAIN] Epoch=2/2, Step=6285/7915, loss=0.562431, lr=2.6e-05, time_each_step=0.16s, eta=0:5:25\n",
      "2021-04-11 11:55:56 [INFO]\t[TRAIN] Epoch=2/2, Step=6485/7915, loss=0.37511, lr=2.3e-05, time_each_step=0.16s, eta=0:4:59\n",
      "2021-04-11 11:56:28 [INFO]\t[TRAIN] Epoch=2/2, Step=6685/7915, loss=1.133521, lr=2e-05, time_each_step=0.16s, eta=0:4:22\n",
      "2021-04-11 11:57:00 [INFO]\t[TRAIN] Epoch=2/2, Step=6885/7915, loss=0.899926, lr=1.7e-05, time_each_step=0.16s, eta=0:3:50\n",
      "2021-04-11 11:57:32 [INFO]\t[TRAIN] Epoch=2/2, Step=7085/7915, loss=0.607618, lr=1.4e-05, time_each_step=0.16s, eta=0:3:17\n",
      "2021-04-11 11:58:04 [INFO]\t[TRAIN] Epoch=2/2, Step=7285/7915, loss=0.540466, lr=1.1e-05, time_each_step=0.16s, eta=0:2:47\n",
      "2021-04-11 11:58:36 [INFO]\t[TRAIN] Epoch=2/2, Step=7485/7915, loss=0.885026, lr=8e-06, time_each_step=0.16s, eta=0:2:15\n",
      "2021-04-11 11:59:08 [INFO]\t[TRAIN] Epoch=2/2, Step=7685/7915, loss=1.083961, lr=4e-06, time_each_step=0.16s, eta=0:1:41\n",
      "2021-04-11 11:59:40 [INFO]\t[TRAIN] Epoch=2/2, Step=7885/7915, loss=1.018951, lr=1e-06, time_each_step=0.16s, eta=0:1:9\n",
      "2021-04-11 11:59:44 [INFO]\t[TRAIN] Epoch 2 finished, loss=0.873988, lr=5.6e-05 .\n",
      "2021-04-11 11:59:44 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/417 [00:00<?, ?it/s]share_vars_from is set, scope is ignored.\n",
      "100%|██████████| 417/417 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 12:00:13 [INFO]\t[EVAL] Finished, Epoch=2, miou=0.47945, category_iou=[0.46155315 0.70654416 0.4655815  0.28412283], oacc=0.67985, category_acc=[0.52320013 0.83825541 0.73018731 0.66777372], kappa=0.551022, category_F1-score=[0.6315927  0.82804087 0.63535395 0.44251659] .\n",
      "2021-04-11 12:00:18 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-04-11 12:00:21 [INFO]\tModel saved in output/deeplab/epoch_2.\n",
      "2021-04-11 12:00:21 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_2, miou=0.4794504089142556\n"
     ]
    }
   ],
   "source": [
    "# 分割类别数\r\n",
    "num_classes = len(train_dataset.labels)\r\n",
    "\r\n",
    "# 构建DeepLabv3p分割器\r\n",
    "model = pdx.seg.DeepLabv3p(\r\n",
    "    num_classes=num_classes,  backbone='Xception65', use_bce_loss=False\r\n",
    ")\r\n",
    "\r\n",
    "# 模型训练\r\n",
    "model.train(\r\n",
    "    num_epochs=2,                 # 训练迭代轮数\r\n",
    "    train_dataset=train_dataset,  # 训练集读取\r\n",
    "    train_batch_size=8,           # 训练时批处理图片数\r\n",
    "    eval_dataset=eval_dataset,    # 验证集读取\r\n",
    "    learning_rate=0.0002,         # 学习率\r\n",
    "    save_interval_epochs=1,       # 保存模型间隔轮次  \r\n",
    "    save_dir='output/deeplab',    # 模型保存路径\r\n",
    "    log_interval_steps=200,       # 日志打印间隔\r\n",
    "    pretrain_weights='output/deeplab/best_model')  #加载预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型评估\n",
    "**evaluate**参数说明：\n",
    "* **eval_dataset (paddlex.datasets)**: 评估数据读取器。\n",
    "* **batch_size (int)**: 评估时的batch大小。默认1。\n",
    "* **epoch_id (int)**: 当前评估模型所在的训练轮数。\n",
    "* **return_details (bool)**: 是否返回详细信息。默认False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/xception.py:316\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-11 12:00:31 [INFO]\tModel[DeepLabv3p] loaded.\n",
      "2021-04-11 12:00:31 [INFO]\tStart to evaluating(total_samples=3332, total_steps=3332)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3332/3332 [00:59<00:00, 55.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('miou', 0.47945041770089064),\n",
       "             ('category_iou',\n",
       "              array([0.46155312, 0.70654416, 0.46558145, 0.28412294])),\n",
       "             ('oacc', 0.6798499638920722),\n",
       "             ('category_acc',\n",
       "              array([0.52320014, 0.83825541, 0.73018719, 0.66777381])),\n",
       "             ('kappa', 0.5510223460923488),\n",
       "             ('category_F1-score',\n",
       "              array([0.63159268, 0.82804087, 0.63535391, 0.44251673]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\r\n",
    "model = pdx.load_model('./output/deeplab/best_model')\r\n",
    "\r\n",
    "# 模型评估\r\n",
    "model.evaluate(eval_dataset, batch_size=1, epoch_id=None, return_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型预测\n",
    "**DeepLabv3p**模型预测接口。需要注意的是，只有在训练过程中定义了eval_dataset，模型在保存时才会将预测时的图像处理流程保存在DeepLabv3p.test_transforms和DeepLabv3p.eval_transforms中。如未在训练时定义eval_dataset，那在调用预测predict接口时，用户需要再重新定义test_transforms传入给predict接口。\n",
    "\n",
    "**predict**参数说明：\n",
    "\n",
    "* **img_file (str|np.ndarray)**: 预测图像路径或numpy数组(HWC排列，BGR格式)。\n",
    "* **transforms (paddlex.seg.transforms)**: 数据预处理操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [01:15<00:00, 61.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\r\n",
    "import cv2\r\n",
    "\r\n",
    "test_base = 'img_testA/'    # 测试集路径\r\n",
    "out_base = 'result/'        # 预测结果保存路径\r\n",
    "\r\n",
    "# 是否存在结果保存路径，如不存在，则创建该路径\r\n",
    "if not os.path.exists(out_base):\r\n",
    "    os.makedirs(out_base)\r\n",
    "\r\n",
    "# 模型预测并保存预测图片\r\n",
    "for im in tqdm(os.listdir(test_base)):\r\n",
    "    if not im.endswith('.jpg'):\r\n",
    "        continue\r\n",
    "    pt = test_base + im\r\n",
    "    result = model.predict(pt)\r\n",
    "    cv2.imwrite(out_base+im.replace('jpg', 'png'), result['label_map'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 其他改进\n",
    "本教程仅提供一个基础的baseline\n",
    "\n",
    "**跑2个epoch（大概45分钟）提交分数大概在47分左右**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c5c5697afebc4ccea054a21db978f041f10a4f9c55f944638ce828b1f649aa57)\n",
    "\n",
    "\n",
    "**跑30个epoch（大概11小时）提交分数在60分左右**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/cbac71e65038433da92f3fe8801fd440391ec6282d36493c8a8b3e278440e0b6)\n",
    "\n",
    "\n",
    "希望参赛者快速跑通整个参赛流程。 参赛者可以针对赛题进行其他改进，例如修改数据预处理方法，修改网络结构，修改训练方式，修改预测结果的后处理等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 由预测结果生成提交文件\r\n",
    "!zip -r result.zip result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 比赛页面传送门： [常规赛：遥感影像地块分割](https://aistudio.baidu.com/aistudio/competition/detail/63)\n",
    "\n",
    "### 欢迎参加 [飞桨领航团实战速成营](https://aistudio.baidu.com/aistudio/education/group/info/16606) 一起学习 ，欢迎一键三连 Fork~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
